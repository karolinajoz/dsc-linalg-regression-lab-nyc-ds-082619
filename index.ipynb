{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Linear Algebra - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll apply regression analysis using simple matrix manipulations to fit a model to given data, and then predict new values for previously unseen data. You'll follow the approach highlighted in the previous lesson where you used Numpy to build the appropriate matrices and vectors and solve for the $\\beta$ (unknown variables) vector. The beta vector will be used with test data to make new predictions. You'll also evaluate the model fit.\n",
    "In order to make this experiment interesting, you'll use NumPy at every single stage of this experiment i.e. loading data, creating matrices, performing test train split, model fitting, and evaluations.\n",
    "  \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Use linear algebra to apply simple regression modeling in Python and NumPy only\n",
    "* Apply train/test split using permutations in NumPy\n",
    "* Use matrix algebra with inverses and dot products to calculate the beta\n",
    "* Make predictions from the fitted model using previously unseen input features \n",
    "* Evaluate the fitted model by calculating the error between real and predicted values\n",
    "\n",
    "\n",
    "First, let's import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # for reading csv file\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "The dataset you'll use for this experiment is \"**Sales Prices in the City of Windsor, Canada**\", something very similar to the Boston Housing dataset. This dataset contains a number of input (independent) variables, including area, number of bedrooms/bathrooms, facilities(AC/garage), etc. and an output (dependent) variable, **price**.  You'll formulate a linear algebra problem to find linear mappings from input to out features using the equation provided in the previous lesson. \n",
    "\n",
    "This will allow you to find a relationship between house features and house price for the given data, allowing you to find unknown prices for houses, given the input features.  \n",
    "\n",
    "A description of the dataset and included features is available [here](https://rdrr.io/cran/Ecdat/man/Housing.html).\n",
    "\n",
    "In your repository, the dataset is available as `windsor_housing.csv` containing the following variables:\n",
    "\n",
    "there are 11 input features (first 11 columns):\n",
    "\n",
    "\tlotsize\tbedrooms  bathrms  stories\tdriveway  recroom\tfullbase  gashw\t airco  garagepl   prefarea\n",
    "\n",
    "and 1 output feature i.e. **price** (12th column). \n",
    "\n",
    "The focus of this lab is not really answering a preset analytical question, but to learn how you can perform a regression experiment, similar to the one you performed in statsmodels, using mathematical manipulations. So you won't be using any Pandas or statsmodels goodness here. The key objectives here are to \n",
    "- understand regression with matrix algebra and \n",
    "- mastery in NumPy scientific computation\n",
    "\n",
    "## Stage 1: Prepare Data for Modeling \n",
    "\n",
    "Let's give you a head start by importing the dataset. You'll perform the following steps to get the data ready for analysis:\n",
    "\n",
    "* Initialize an empty list `data` for loading data\n",
    "* Read the csv file containing complete (raw) `windsor_housing.csv`. [Use `csv.reader()` for loading data.](https://docs.python.org/3/library/csv.html). Store this in `data` one row at a time.\n",
    "\n",
    "* Drop the first row of csv file as it contains the names of variables (header) which won't be used during analysis (keeping this will cause errors as it contains text values).\n",
    "\n",
    "* Append a column of all 1s to the data (bias) as the first column\n",
    "\n",
    "* Convert `data` to a Numpy array and inspect first few rows \n",
    "\n",
    "NOTE: `read.csv()` reads the csv as a text file, so you should convert the contents to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 5.85e+03, 3.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
       "        0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
       "        4.20e+04],\n",
       "       [1.00e+00, 4.00e+03, 2.00e+00, 1.00e+00, 1.00e+00, 1.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        3.85e+04],\n",
       "       [1.00e+00, 3.06e+03, 3.00e+00, 1.00e+00, 1.00e+00, 1.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        4.95e+04],\n",
       "       [1.00e+00, 6.65e+03, 3.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
       "        1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        6.05e+04],\n",
       "       [1.00e+00, 6.36e+03, 2.00e+00, 1.00e+00, 1.00e+00, 1.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        6.10e+04]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code here\n",
    "import numpy as np\n",
    "data =[]\n",
    "\n",
    "import csv\n",
    "with open('windsor_housing.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        ones = [1]\n",
    "        for r in row:\n",
    "            ones.append(float(r))\n",
    "        data.append(ones)\n",
    "data = np.array(data)\n",
    "data[:5,:]\n",
    "\n",
    "# First 5 rows of raw data \n",
    "\n",
    "# array([[1.00e+00, 5.85e+03, 3.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
    "#         0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
    "#         4.20e+04],\n",
    "#        [1.00e+00, 4.00e+03, 2.00e+00, 1.00e+00, 1.00e+00, 1.00e+00,\n",
    "#         0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
    "#         3.85e+04],\n",
    "#        [1.00e+00, 3.06e+03, 3.00e+00, 1.00e+00, 1.00e+00, 1.00e+00,\n",
    "#         0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
    "#         4.95e+04],\n",
    "#        [1.00e+00, 6.65e+03, 3.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
    "#         1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
    "#         6.05e+04],\n",
    "#        [1.00e+00, 6.36e+03, 2.00e+00, 1.00e+00, 1.00e+00, 1.00e+00,\n",
    "#         0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
    "#         6.10e+04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Perform a 80/20 test train Split\n",
    "\n",
    "Explore NumPy's official documentation to manually split a dataset using a random sampling method of your choice. Some useful methods are located in the [numpy.random library](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html).\n",
    "* Perform a **random** 80/20 split on data using a method of your choice in NumPy\n",
    "* Create x_test, y_test, x_train and y_train arrays from the split data\n",
    "* Inspect the contents to see if the split performed as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545]\n"
     ]
    }
   ],
   "source": [
    "# Your code here \n",
    "# Make array of indices\n",
    "indexes = np.arange(data.shape[0])\n",
    "# Randomly choose 80% subset of indices without replacement for training\n",
    "training_idx = np.random.choice(indexes, size=round(546*.8), replace=False)\n",
    "# Choose remaining 20% of indices for testing\n",
    "test_idx = all_idx[~np.isin(all_idx, training_idx)]\n",
    "# Subset data \n",
    "training, test = data[training_idx,:], data[test_idx,:]\n",
    "\n",
    "# Split results\n",
    "\n",
    "# Raw data Shape:  (546, 13)\n",
    "# Train/Test Split: (437, 13) (109, 13)\n",
    "# x_train, y_train, x_test, y_test: (437, 12) (437,) (109, 12) (109,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate the `beta` \n",
    "\n",
    "With $X$ and $y$ in place, you can now compute your beta values with $x_\\text{train}$ and $y_\\text{train}$ as:\n",
    "#### $\\beta = (x_\\text{train}^T. x_\\text{train})^{-1} . x_\\text{train}^T . y_\\text{train}$\n",
    "\n",
    "* Using numpy operations (transpose, inverse) that we saw earlier, compute the above equation in steps.\n",
    "* Print your beta values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "\n",
    "\n",
    "\n",
    "# Calculated beta values\n",
    "\n",
    "\n",
    "# Due to random split, your answers may vary \n",
    "# [-4.48935874e+03  3.25291905e+00  2.51041471e+03  1.38887244e+04\n",
    "#  6.36181829e+03  7.97134681e+03  6.73696187e+03  4.00955575e+03\n",
    "#  8.67978657e+03  1.26886121e+04  4.20044707e+03  8.63557510e+03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Make Predictions\n",
    "Great, you now have a set of coefficients that describe the linear mappings between $X$ and $y$. You can now use the calculated beta values with the test datasets that we left out to calculate $y$ predictions. Next, use all features in turn and multiply it with this beta. The result will give a prediction for each row which you can append to a new array of predictions.\n",
    "\n",
    "$\\hat{y} = x\\beta = \\beta_0 + \\beta_1 x_1 +  \\beta_2 x_2 + \\ldots + \\beta_m x_m $ \n",
    "\n",
    "* Create a new empty list (`y_pred`) for saving predictions\n",
    "* For each row of x_test, take the dot product of the row with beta to calculate the prediction for that row\n",
    "* Append the predictions to `y_pred`\n",
    "* Print the new set of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Model \n",
    "\n",
    "### Visualize Actual vs. Predicted values\n",
    "This is exciting, now your model can use the beta value to predict the price of houses given the input features. Let's plot these predictions against the actual values in `y_test` to see how much our model deviates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted and actual values as line plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/diff.png\" width=\"750\">\n",
    "\n",
    "This doesn't look so bad, does it? Your model, although isn't perfect at this stage, is making a good attempt to predict house prices although a few prediction seem a bit out. There could be a number of reasons for this. Let's try to dig a bit deeper to check model's predictive abilities by comparing these prediction with actual values of `y_test` individually. That will help you calculate the RMSE value (Root Mean Squared Error) for your model. \n",
    "### Root Mean Squared Error\n",
    "Here is the formula for this again. \n",
    "\n",
    "$$ \\large RMSE = \\sqrt{\\sum^N_{i=1}\\dfrac{ (\\text{Predicted}_i-\\text{Actual}_i)^2}{N}}$$\n",
    "\n",
    "* Initialize an empty array `err`\n",
    "* for each row in `y_test` and `y_pred`, take the squared difference and append error for each row in the `err` array\n",
    "* Calculate $RMSE$ from `err` using the formula shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "\n",
    "# Due to random split, your answers may vary \n",
    "\n",
    "# RMSE = 16585.59639547113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Root Mean Squared Error\n",
    "The above error is clearly in terms of the dependent variable i.e. the final house price. You can also use a normalized mean squared error in case of multiple regression which can be calculated from RMSE using following the formula:\n",
    "\n",
    "* Calculate normalized Root Mean Squared Error\n",
    "\n",
    "\n",
    "$$ \\large NRMSE = \\dfrac{RMSE}{max_i y_i - min_i y_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NRMSE\n",
    "\n",
    "# Due to random split, your answers may vary \n",
    "\n",
    "# 0.10051876603315836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There it is. A complete multiple regression analysis using nothing but Numpy. Having good programming skills in numpy allows you to dig deeper into analytical algorithms in machine learning and deep learning. Using matrix multiplication techniques you saw here, you can easily build a whole neural network from scratch. \n",
    "\n",
    "## Level up - Optional \n",
    "\n",
    "* Calculate the R_squared and adjusted R_squared for the above experiment\n",
    "* Plot the residuals (similar to statsmodels) and comment on the variance and heteroscedasticity\n",
    "* Run the experiment in statsmodels and compare the performance of both approaches in terms of computational cost\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, you built a predictive model for predicting house prices. Remember this is a very naive implementation of regression modeling. The purpose here was to get an introduction to the applications of linear algebra into machine learning and predictive analysis. There are still have a number of shortcomings in this modeling approach and you can further apply a number of data modeling techniques to improve this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
